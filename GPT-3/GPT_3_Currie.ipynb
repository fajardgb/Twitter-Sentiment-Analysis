{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This ipynb is for testing GPT-3 on politcian tweets dataset using OpenAI API. The API key is omitted on this repo for security reasons, so the code won't be able to run without it."
      ],
      "metadata": {
        "id": "6yjXeLYbetWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czYQeBohpN4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb98adaa-9075-4d39-d95d-899bdbc98d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 991 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=8a389417d0361a290487921974adca6f169b5bbe937eceb3c0523b66893d0721\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from pandas import DataFrame as df\n",
        "from tqdm import tqdm # for progress bar on classify()\n",
        "from openai.error import RateLimitError # need to catch error for sending too many inputs to api endpoint\n"
      ],
      "metadata": {
        "id": "VpTgnXuvpe6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this api key and model id to get the fine-tuned Currie model on Kenny's account\n",
        "# API for reference: https://beta.openai.com/docs/introduction/overview\n",
        "\n",
        "OPENAI_API_KEY = ''\n",
        "MODEL_ID = 'curie:ft-personal:kenny-2022-12-05-22-56-57'\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "openai.api_key = OPENAI_API_KEY\n"
      ],
      "metadata": {
        "id": "GaozntcPp7pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "TRAIN_SIZE = 0.8"
      ],
      "metadata": {
        "id": "FfMEwq54__pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Information about model\n",
        "openai.Model.retrieve(MODEL_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_bL8FROCOwJ",
        "outputId": "8857f406-5705-42d0-f95e-106753e3bb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Model model id=curie:ft-personal:kenny-2022-12-05-22-56-57 at 0x7f464e072b80> JSON: {\n",
              "  \"created\": 1670281017,\n",
              "  \"id\": \"curie:ft-personal:kenny-2022-12-05-22-56-57\",\n",
              "  \"object\": \"model\",\n",
              "  \"owned_by\": \"user-ypuc5pkpnmenuviu5z9ehvwp\",\n",
              "  \"parent\": \"curie:2020-05-03\",\n",
              "  \"permission\": [\n",
              "    {\n",
              "      \"allow_create_engine\": true,\n",
              "      \"allow_fine_tuning\": true,\n",
              "      \"allow_logprobs\": true,\n",
              "      \"allow_sampling\": true,\n",
              "      \"allow_search_indices\": false,\n",
              "      \"allow_view\": true,\n",
              "      \"created\": 1670281017,\n",
              "      \"group\": null,\n",
              "      \"id\": \"snapperm-hniCnmUTAHh9wohEcQJJW8mH\",\n",
              "      \"is_blocking\": false,\n",
              "      \"object\": \"model_permission\",\n",
              "      \"organization\": \"org-rvWBJysoXs405lvjgSp1U88F\"\n",
              "    }\n",
              "  ],\n",
              "  \"root\": \"curie:2020-05-03\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZQ6Yz-j-9ZK",
        "outputId": "15fa43df-cfaf-4d75-b4ec-7049e32c4aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD POLITICIANS TWEETS\n",
        "twt_load_dir = '/content/drive/MyDrive/Twitter/'\n",
        "\n",
        "# tweets regarding the politicans\n",
        "mehmet_oz_df = pd.read_csv(twt_load_dir+\"adam_laxalt.csv\", encoding =DATASET_ENCODING)\n",
        "john_fetterman_df = pd.read_csv(twt_load_dir+\"john_fetterman.csv\")\n",
        "adam_laxalt_df = pd.read_csv(twt_load_dir+\"adam_laxalt.csv\")\n",
        "catherine_cortez_masto_df = pd.read_csv(twt_load_dir+\"catherine_cortez_masto.csv\")\n",
        "ron_johnson_df = pd.read_csv(twt_load_dir+\"ron_johnson.csv\")\n",
        "mandela_barnes_df = pd.read_csv(twt_load_dir+\"mandela_barnes.csv\")\n",
        "donald_bolduc_df = pd.read_csv(twt_load_dir+\"donald_bolduc.csv\")\n",
        "maggie_hassan_df = pd.read_csv(twt_load_dir+\"maggie_hassan.csv\")\n",
        "ted_budd_df = pd.read_csv(twt_load_dir+\"ted_budd.csv\")\n",
        "cheri_beasly_df = pd.read_csv(twt_load_dir+\"cheri_beasly.csv\")\n",
        "joe_pinion_df = pd.read_csv(twt_load_dir+\"joe_pinion.csv\")\n",
        "charles_schumer_df = pd.read_csv(twt_load_dir+\"charles_schumer.csv\")\n",
        "jd_vance_df = pd.read_csv(twt_load_dir+\"jd_vance.csv\")\n",
        "tim_ryan_df = pd.read_csv(twt_load_dir+\"tim_ryan.csv\")"
      ],
      "metadata": {
        "id": "Bxw8ZtiE_H1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mehmet_oz_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in mehmet_oz_df['Tweet']]\n",
        "john_fetterman_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in john_fetterman_df['Tweet']]\n",
        "adam_laxalt_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in adam_laxalt_df['Tweet']]\n",
        "catherine_cortez_masto_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in catherine_cortez_masto_df['Tweet']]\n",
        "ron_johnson_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in ron_johnson_df['Tweet']]\n",
        "mandela_barnes_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in mandela_barnes_df['Tweet']]\n",
        "donald_bolduc_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in donald_bolduc_df['Tweet']]\n",
        "maggie_hassan_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in maggie_hassan_df['Tweet']]\n",
        "ted_budd_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in ted_budd_df['Tweet']]\n",
        "cheri_beasly_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in cheri_beasly_df['Tweet']]\n",
        "joe_pinion_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in joe_pinion_df['Tweet']]\n",
        "charles_schumer_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in charles_schumer_df['Tweet']]\n",
        "jd_vance_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in jd_vance_df['Tweet']]\n",
        "tim_ryan_df['Tweet'] = [t+'\\n\\n###\\n\\n' for t in tim_ryan_df['Tweet']]"
      ],
      "metadata": {
        "id": "EMXUdW19AdO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to get completion of given prompt and model\n",
        "def completion(prompt,model):\n",
        "  response = openai.Completion.create(\n",
        "              model=model,\n",
        "              prompt=prompt+\"\\n\\n###\\n\\n\",\n",
        "              max_tokens=1,\n",
        "              temperature=0\n",
        "            )\n",
        "  return response.to_dict()['choices'][0]['text'][1:]\n",
        "\n",
        "# Use this to get classifications of all political tweets. Returns % positive\n",
        "def classify(model,df):\n",
        "  tqdm.pandas(desc=\"Classfication Progress\")\n",
        "  total_pos = 0\n",
        "  total = 0\n",
        "  tweets = df['Tweet']\n",
        "  \n",
        "  for tweet in tqdm(tweets,total=len(tweets)):\n",
        "    total += 1\n",
        "    # Can only perform 60 completions per minute, so we must handle RateLimitError to set a cool-down time\n",
        "    while True:\n",
        "      try:\n",
        "        result = completion(tweet,model)\n",
        "      except RateLimitError:\n",
        "        #print('Encountered RateLimitError: Waiting for 65 seconds...')\n",
        "        print(f'Current Positive Rate: {total_pos/total}')\n",
        "        time.sleep(65)\n",
        "        continue\n",
        "      break \n",
        "\n",
        "    if 'positive' in result: # currie will return result as string in the form of 'positive###' or 'negative###'\n",
        "      total_pos += 1\n",
        "\n",
        "  return total_pos/len(df)"
      ],
      "metadata": {
        "id": "W_cPUdGTqilp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to begin classification \n",
        "# This will take about (# of tweets / 60) minutes to complete\n",
        "print(\"Oz:\")\n",
        "classify(MODEL_ID,mehmet_oz_df)"
      ],
      "metadata": {
        "id": "SM6BkViuqe99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b51c4e4-9db9-4b3a-ea0d-06900ec0e35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 220/220 [00:24<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6590909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fetterman:\")\n",
        "classify(MODEL_ID,john_fetterman_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEk-R91AH0Tm",
        "outputId": "6b08b10b-972c-4220-8025-05a7692cead3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetterman:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.99it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Laxalt:\")\n",
        "classify(MODEL_ID,adam_laxalt_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGPnRpsyK83V",
        "outputId": "bc4b75c4-0885-4799-b562-7a98bafdf0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laxalt:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 220/220 [00:14<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6590909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cortez:\")\n",
        "classify(MODEL_ID,catherine_cortez_masto_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn8hfEBSLB_a",
        "outputId": "1ad3559b-5065-4b47-df3f-8c07aaf85ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cortez:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130/130 [00:09<00:00, 14.39it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7692307692307693"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Johnson:\")\n",
        "classify(MODEL_ID,ron_johnson_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIPZslZzLFMb",
        "outputId": "299d89ed-640a-498a-d2ea-58321f0f54df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Johnson:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:35<00:00, 14.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Barnes:\")\n",
        "classify(MODEL_ID,mandela_barnes_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14TuYCxdLHHa",
        "outputId": "e7ec88ef-c3fd-4b8d-dff4-2b2fe4b7e0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barnes:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 440/440 [00:28<00:00, 15.31it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38636363636363635"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bolduc:\")\n",
        "classify(MODEL_ID,donald_bolduc_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9WcvoGLIje",
        "outputId": "a163635f-11b1-41ef-ea00-d47591bb1809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bolduc:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:01<00:00, 13.93it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hassan:\")\n",
        "classify(MODEL_ID,maggie_hassan_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7dSTpNWLKBj",
        "outputId": "e37d1b8f-97d7-4622-9b34-956768cc14c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hassan:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130/130 [00:08<00:00, 14.68it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19230769230769232"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Budd:\")\n",
        "classify(MODEL_ID,ted_budd_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBWRSkyHLLWM",
        "outputId": "364af326-499d-44b1-cbb0-7f86a613479e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Budd:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.85it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.78"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Beasly:\")\n",
        "classify(MODEL_ID,cheri_beasly_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBP9GAKfLMwF",
        "outputId": "b2058ba3-cf0e-4a9e-f6d3-60e4030008f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beasly:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 165/165 [00:11<00:00, 14.76it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48484848484848486"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pinion:\")\n",
        "classify(MODEL_ID,joe_pinion_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8QnBlrDLOQ9",
        "outputId": "bd1bb256-33d6-46a6-d9c2-254c6fba1ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinion:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:03<00:00, 15.12it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Schumer:\")\n",
        "classify(MODEL_ID,charles_schumer_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrYq1wDwLPiu",
        "outputId": "2e9affd8-f5ad-4f06-ac71-6841b1d866bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schumer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [00:11<00:00, 14.83it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8857142857142857"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vance:\")\n",
        "classify(MODEL_ID,jd_vance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA9NAdUTLQ6O",
        "outputId": "978e6dbd-e184-4694-854c-8b2efe195aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vance:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.96it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.53"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ryan:\")\n",
        "classify(MODEL_ID,tim_ryan_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2WMngGALScr",
        "outputId": "68ae57b7-b0ee-42cb-b612-0f55f659b7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ryan:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:32<00:00, 15.16it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.58"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}