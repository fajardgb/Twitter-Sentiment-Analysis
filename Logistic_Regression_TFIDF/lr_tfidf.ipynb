{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /usr/local/lib/python3.9/site-packages (from scipy) (1.23.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/data/sampled/training.1600000.processed.noemoticon.csv\", encoding = \"latin-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2265878782</td>\n",
       "      <td>Sun Jun 21 07:29:15 PDT 2009</td>\n",
       "      <td>MeeJong</td>\n",
       "      <td>This morning my daughter asked me if I hate my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2205565064</td>\n",
       "      <td>Wed Jun 17 05:00:35 PDT 2009</td>\n",
       "      <td>kathysyahrizal</td>\n",
       "      <td>I forgot to charge my bb, zzzzz only 35% left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002872654</td>\n",
       "      <td>Tue Jun 02 05:22:07 PDT 2009</td>\n",
       "      <td>kgautam</td>\n",
       "      <td>my MBP battery is fluctuating between dead to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1835496893</td>\n",
       "      <td>Mon May 18 06:07:33 PDT 2009</td>\n",
       "      <td>thejanice</td>\n",
       "      <td>i really wish my landlord would call me back. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573596472</td>\n",
       "      <td>Tue Apr 21 01:55:46 PDT 2009</td>\n",
       "      <td>lucyxechelon</td>\n",
       "      <td>mean blog people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids                          date            user  \\\n",
       "0  2265878782  Sun Jun 21 07:29:15 PDT 2009         MeeJong   \n",
       "1  2205565064  Wed Jun 17 05:00:35 PDT 2009  kathysyahrizal   \n",
       "2  2002872654  Tue Jun 02 05:22:07 PDT 2009         kgautam   \n",
       "3  1835496893  Mon May 18 06:07:33 PDT 2009       thejanice   \n",
       "4  1573596472  Tue Apr 21 01:55:46 PDT 2009    lucyxechelon   \n",
       "\n",
       "                                                text  target  \n",
       "0  This morning my daughter asked me if I hate my...       0  \n",
       "1     I forgot to charge my bb, zzzzz only 35% left        0  \n",
       "2  my MBP battery is fluctuating between dead to ...       0  \n",
       "3  i really wish my landlord would call me back. ...       0  \n",
       "4                                  mean blog people        0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf = TfidfVectorizer(min_df=5, max_df=0.8, sublinear_tf=True, use_idf=True)\n",
    "train_x_tfidf = tfidf.fit_transform(X_train)\n",
    "test_x_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def logistic_regression(train_x, train_y):\n",
    "  classifier = LogisticRegression(max_iter=100000)\n",
    "  classifier.fit(train_x, train_y)\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.043915033340454 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression\n",
    "import time\n",
    "start_time = time.time()\n",
    "classifier = logistic_regression(train_x_tfidf, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets regarding the politicans\n",
    "mehmet_oz_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/mehmet_oz.csv\")\n",
    "john_fetterman_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/john_fetterman.csv\")\n",
    "adam_laxalt_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/adam_laxalt.csv\")\n",
    "catherine_cortez_masto_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/catherine_cortez_masto.csv\")\n",
    "ron_johnson_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/ron_johnson.csv\")\n",
    "mandela_barnes_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/mandela_barnes.csv\")\n",
    "donald_bolduc_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/donald_bolduc.csv\")\n",
    "maggie_hassan_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/maggie_hassan.csv\")\n",
    "ted_budd_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/ted_budd.csv\")\n",
    "cheri_beasly_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/cheri_beasly.csv\")\n",
    "joe_pinion_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/joe_pinion.csv\")\n",
    "charles_schumer_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/charles_schumer.csv\")\n",
    "jd_vance_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/jd_vance.csv\")\n",
    "tim_ryan_df = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Github_Repos/Twitter-Sentiment-Analysis/twitter_api/twitter_api_data/original/tim_ryan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.6493101119995117 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# do tfidf on the tweets\n",
    "# get the time\n",
    "start_time = time.time()\n",
    "mehmet_oz_tfidf = tfidf.transform(mehmet_oz_df['Tweet'])\n",
    "john_fetterman_tfidf = tfidf.transform(john_fetterman_df['Tweet'])\n",
    "adam_laxalt_tfidf = tfidf.transform(adam_laxalt_df['Tweet'])\n",
    "catherine_cortez_masto_tfidf = tfidf.transform(catherine_cortez_masto_df['Tweet'])\n",
    "ron_johnson_tfidf = tfidf.transform(ron_johnson_df['Tweet'])\n",
    "mandela_barnes_tfidf = tfidf.transform(mandela_barnes_df['Tweet'])\n",
    "donald_bolduc_tfidf = tfidf.transform(donald_bolduc_df['Tweet'])\n",
    "maggie_hassan_tfidf = tfidf.transform(maggie_hassan_df['Tweet'])\n",
    "ted_budd_tfidf = tfidf.transform(ted_budd_df['Tweet'])\n",
    "cheri_beasly_tfidf = tfidf.transform(cheri_beasly_df['Tweet'])\n",
    "joe_pinion_tfidf = tfidf.transform(joe_pinion_df['Tweet'])\n",
    "charles_schumer_tfidf = tfidf.transform(charles_schumer_df['Tweet'])\n",
    "jd_vance_tfidf = tfidf.transform(jd_vance_df['Tweet'])\n",
    "tim_ryan_tfidf = tfidf.transform(tim_ryan_df['Tweet'])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic Regression to predict the sentiment of the tweets and label them as 1 or 0 on sentiment column\n",
    "def get_predict(classifier, tweets_tfidf, tweets):\n",
    "      sentiment = classifier.predict(tweets_tfidf)\n",
    "      tweets['sentiment'] = sentiment\n",
    "      return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.032337188720703125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# get the time\n",
    "start_time = time.time()\n",
    "mehmet_oz_predict = get_predict(classifier, mehmet_oz_tfidf, mehmet_oz_df)\n",
    "john_fetterman_predict = get_predict(classifier, john_fetterman_tfidf, john_fetterman_df)\n",
    "adam_laxalt_predict = get_predict(classifier, adam_laxalt_tfidf, adam_laxalt_df)\n",
    "catherine_cortez_masto_predict = get_predict(classifier, catherine_cortez_masto_tfidf, catherine_cortez_masto_df)\n",
    "ron_johnson_predict = get_predict(classifier, ron_johnson_tfidf, ron_johnson_df)\n",
    "mandela_barnes_predict = get_predict(classifier, mandela_barnes_tfidf, mandela_barnes_df)\n",
    "donald_bolduc_predict = get_predict(classifier, donald_bolduc_tfidf, donald_bolduc_df)\n",
    "maggie_hassan_predict = get_predict(classifier, maggie_hassan_tfidf, maggie_hassan_df)\n",
    "ted_budd_predict = get_predict(classifier, ted_budd_tfidf, ted_budd_df)\n",
    "cheri_beasly_predict = get_predict(classifier, cheri_beasly_tfidf, cheri_beasly_df)\n",
    "joe_pinion_predict = get_predict(classifier, joe_pinion_tfidf, joe_pinion_df)\n",
    "charles_schumer_predict = get_predict(classifier, charles_schumer_tfidf, charles_schumer_df)\n",
    "jd_vance_predict = get_predict(classifier, jd_vance_tfidf, jd_vance_df)\n",
    "tim_ryan_predict = get_predict(classifier, tim_ryan_tfidf, tim_ryan_df)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of positive and negatives tweets from each df\n",
    "def get_sentiment(df):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['sentiment'] == 0:\n",
    "            neg += 1\n",
    "        else:\n",
    "            pos += 1\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehmet Oz:  145 165\n",
      "John Fetterman:  340 160\n",
      "Adam Laxalt:  85 135\n",
      "Catherine Cortez Masto:  80 50\n",
      "Ron Johnson:  500 0\n",
      "Mandela Barnes:  230 210\n",
      "Donald Bolduc:  5 20\n",
      "Maggie Hassan:  100 30\n",
      "Ted Budd:  395 105\n",
      "Cheri Beasley:  140 25\n",
      "Joe Pinion:  35 15\n",
      "Charles Schumer:  145 30\n",
      "JD Vance:  330 170\n",
      "Tim Ryan:  355 145\n"
     ]
    }
   ],
   "source": [
    "# get number of positive and negative tweets from each politician\n",
    "# get number of positive and negatives tweets from each df\n",
    "pos, neg = get_sentiment(mehmet_oz_predict)\n",
    "print(\"Mehmet Oz: \", pos, neg)\n",
    "pos, neg = get_sentiment(john_fetterman_predict)\n",
    "print(\"John Fetterman: \", pos, neg)\n",
    "pos, neg = get_sentiment(adam_laxalt_predict)\n",
    "print(\"Adam Laxalt: \", pos, neg)\n",
    "pos, neg = get_sentiment(catherine_cortez_masto_predict)\n",
    "print(\"Catherine Cortez Masto: \", pos, neg)\n",
    "pos, neg = get_sentiment(ron_johnson_predict)\n",
    "print(\"Ron Johnson: \", pos, neg)\n",
    "pos, neg = get_sentiment(mandela_barnes_predict)\n",
    "print(\"Mandela Barnes: \", pos, neg)\n",
    "pos, neg = get_sentiment(donald_bolduc_predict)\n",
    "print(\"Donald Bolduc: \", pos, neg)\n",
    "pos, neg = get_sentiment(maggie_hassan_predict)\n",
    "print(\"Maggie Hassan: \", pos, neg)\n",
    "pos, neg = get_sentiment(ted_budd_predict)\n",
    "print(\"Ted Budd: \", pos, neg)\n",
    "pos, neg = get_sentiment(cheri_beasly_predict)\n",
    "print(\"Cheri Beasley: \", pos, neg)\n",
    "pos, neg = get_sentiment(joe_pinion_predict)\n",
    "print(\"Joe Pinion: \", pos, neg)\n",
    "pos, neg = get_sentiment(charles_schumer_predict)\n",
    "print(\"Charles Schumer: \", pos, neg)\n",
    "pos, neg = get_sentiment(jd_vance_predict)\n",
    "print(\"JD Vance: \", pos, neg)\n",
    "pos, neg = get_sentiment(tim_ryan_predict)\n",
    "print(\"Tim Ryan: \", pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pos/neg ,pos/all, neg/all ratio for all dfs\n",
    "def get_ratios(df):\n",
    "    pos, neg = get_sentiment(df)\n",
    "    pos_all = pos / (pos + neg)\n",
    "    neg_all = neg / (pos + neg)\n",
    "    # if neg is 0, make it equal to 1\n",
    "    if neg == 0:\n",
    "        neg = 1\n",
    "    pos_neg = pos / neg\n",
    "    # round all ratios to 2 decimal places\n",
    "    pos_all = round(pos_all, 2)\n",
    "    neg_all = round(neg_all, 2)\n",
    "    pos_neg = round(pos_neg, 2)\n",
    "    return pos_all, neg_all, pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehmet Oz:  0.47 0.53 0.88\n",
      "John Fetterman:  0.68 0.32 2.12\n",
      "Adam Laxalt:  0.39 0.61 0.63\n",
      "Catherine Cortez Masto:  0.62 0.38 1.6\n",
      "Ron Johnson:  1.0 0.0 500.0\n",
      "Mandela Barnes:  0.52 0.48 1.1\n",
      "Donald Bolduc:  0.2 0.8 0.25\n",
      "Maggie Hassan:  0.77 0.23 3.33\n",
      "Ted Budd:  0.79 0.21 3.76\n",
      "Cheri Beasley:  0.85 0.15 5.6\n",
      "Joe Pinion:  0.7 0.3 2.33\n",
      "Charles Schumer:  0.83 0.17 4.83\n",
      "JD Vance:  0.66 0.34 1.94\n",
      "Tim Ryan:  0.71 0.29 2.45\n"
     ]
    }
   ],
   "source": [
    "pos_all, neg_all, pos_neg = get_ratios(mehmet_oz_predict)\n",
    "print(\"Mehmet Oz: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(john_fetterman_predict)\n",
    "print(\"John Fetterman: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(adam_laxalt_predict)\n",
    "print(\"Adam Laxalt: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(catherine_cortez_masto_predict)\n",
    "print(\"Catherine Cortez Masto: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(ron_johnson_predict)\n",
    "print(\"Ron Johnson: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(mandela_barnes_predict)\n",
    "print(\"Mandela Barnes: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(donald_bolduc_predict)\n",
    "print(\"Donald Bolduc: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(maggie_hassan_predict)\n",
    "print(\"Maggie Hassan: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(ted_budd_predict)\n",
    "print(\"Ted Budd: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(cheri_beasly_predict)\n",
    "print(\"Cheri Beasley: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(joe_pinion_predict)\n",
    "print(\"Joe Pinion: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(charles_schumer_predict)\n",
    "print(\"Charles Schumer: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(jd_vance_predict)\n",
    "print(\"JD Vance: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = get_ratios(tim_ryan_predict)\n",
    "print(\"Tim Ryan: \", pos_all, neg_all, pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winners vs losers\n",
    "# winners: john fetterman, catherine cortez masto, ron johnson, maggie hassan, ted budd, charles schumer, jd vance\n",
    "# losers: mehmet oz, adam laxalt, mandela barnes, donald bolduc, cheri beasley, joe pinion, tim ryan\n",
    "winners = [john_fetterman_predict, catherine_cortez_masto_predict, ron_johnson_predict, maggie_hassan_predict, ted_budd_predict, charles_schumer_predict, jd_vance_predict]\n",
    "losers = [mehmet_oz_predict, adam_laxalt_predict, mandela_barnes_predict, donald_bolduc_predict, cheri_beasly_predict, joe_pinion_predict, tim_ryan_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum number of positive and negatives tweets from list of df\n",
    "def sum_sentiment(dfs):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for df in dfs:\n",
    "        pos_df, neg_df = get_sentiment(df)\n",
    "        pos += pos_df\n",
    "        neg += neg_df\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winners:  1890 545\n",
      "Losers:  995 715\n"
     ]
    }
   ],
   "source": [
    "pos, neg = sum_sentiment(winners)\n",
    "print(\"Winners: \", pos, neg)\n",
    "pos, neg = sum_sentiment(losers)\n",
    "print(\"Losers: \", pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the ratios of winners and losers\n",
    "def avg_ratios(dfs):\n",
    "    pos_all = 0\n",
    "    neg_all = 0\n",
    "    pos_neg = 0\n",
    "    for df in dfs:\n",
    "        pos_all_df, neg_all_df, pos_neg_df = get_ratios(df)\n",
    "        pos_all += pos_all_df\n",
    "        neg_all += neg_all_df\n",
    "        pos_neg += pos_neg_df\n",
    "    pos_all = pos_all / len(dfs)\n",
    "    neg_all = neg_all / len(dfs)\n",
    "    pos_neg = pos_neg / len(dfs)\n",
    "    return pos_all, neg_all, pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winners:  0.7642857142857142 0.2357142857142857 73.94000000000001\n",
      "Losers:  0.5485714285714286 0.4514285714285714 1.8914285714285717\n"
     ]
    }
   ],
   "source": [
    "pos_all, neg_all, pos_neg = avg_ratios(winners)\n",
    "print(\"Winners: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = avg_ratios(losers)\n",
    "print(\"Losers: \", pos_all, neg_all, pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# democrats vs republicans\n",
    "# democrats: mehmet oz, adam laxalt, ron johnson, donald bolduc, ted budd, joe pinion, jd vance\n",
    "# republicans: john fetterman, catherine cortez masto, mandela barnes, maggie hassan, cheri beasley, charles schumer, tim ryan\n",
    "dems = [mehmet_oz_predict, adam_laxalt_predict, ron_johnson_predict, donald_bolduc_predict, ted_budd_predict, joe_pinion_predict, jd_vance_predict]\n",
    "reps = [john_fetterman_predict, catherine_cortez_masto_predict, mandela_barnes_predict, maggie_hassan_predict, cheri_beasly_predict, charles_schumer_predict, tim_ryan_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrats:  1495 610\n",
      "Republicans:  1390 650\n"
     ]
    }
   ],
   "source": [
    "pos, neg = sum_sentiment(dems)\n",
    "print(\"Democrats: \", pos, neg)\n",
    "pos, neg = sum_sentiment(reps)\n",
    "print(\"Republicans: \", pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrats:  0.6014285714285714 0.3985714285714286 72.82714285714285\n",
      "Republicans:  0.7114285714285714 0.28857142857142853 3.004285714285714\n"
     ]
    }
   ],
   "source": [
    "pos_all, neg_all, pos_neg = avg_ratios(dems)\n",
    "print(\"Democrats: \", pos_all, neg_all, pos_neg)\n",
    "pos_all, neg_all, pos_neg = avg_ratios(reps)\n",
    "print(\"Republicans: \", pos_all, neg_all, pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all dfs to csv\n",
    "john_fetterman_predict.to_csv(\"john_fetterman_lr_annotated.csv\")\n",
    "mehmet_oz_predict.to_csv(\"mehmet_oz_lr_annotated.csv\")\n",
    "adam_laxalt_predict.to_csv(\"adam_laxalt_lr_annotated.csv\")\n",
    "catherine_cortez_masto_predict.to_csv(\"catherine_cortez_masto_lr_annotated.csv\")\n",
    "ron_johnson_predict.to_csv(\"ron_johnson_lr_annotated.csv\")\n",
    "mandela_barnes_predict.to_csv(\"mandela_barnes_lr_annotated.csv\")\n",
    "donald_bolduc_predict.to_csv(\"donald_bolduc_lr_annotated.csv\")\n",
    "maggie_hassan_predict.to_csv(\"maggie_hassan_lr_annotated.csv\")\n",
    "ted_budd_predict.to_csv(\"ted_budd_lr_annotated.csv\")\n",
    "cheri_beasly_predict.to_csv(\"cheri_beasly_lr_annotated.csv\")\n",
    "joe_pinion_predict.to_csv(\"joe_pinion_lr_annotated.csv\")\n",
    "charles_schumer_predict.to_csv(\"charles_schumer_lr_annotated.csv\")\n",
    "jd_vance_predict.to_csv(\"jd_vance_lr_annotated.csv\")\n",
    "tim_ryan_predict.to_csv(\"tim_ryan_lr_annotated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
